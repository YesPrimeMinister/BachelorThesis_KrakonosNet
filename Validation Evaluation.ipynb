{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]]\n",
      "(1088,)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\dd\\\\Documents\\\\NATUR_CUNI\\\\_bc\\\\Validace\\\\Validace.csv', sep=',')\n",
    "print(df.values)\n",
    "arr = df.to_numpy(np.uint8)\n",
    "classified = arr[:,0]\n",
    "validace = arr[:,1]\n",
    "print(validace.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_metrics(Y, y, C):\n",
    "    # Copy the code from the last lab here\n",
    "    ##########################################################\n",
    "    M = np.equal(Y,y).astype(np.int)\n",
    "    TP = np.array([np.sum( M * (Y==i).astype(np.int)) for i in range(C)])\n",
    "    FP = np.array([np.sum( (1-M) * (Y==i)) for i in range(C)])\n",
    "    FN = np.array([np.sum( (1-M) * (y==i)) for i in range(C)])\n",
    "\n",
    "    precisions = TP/(TP+FP)\n",
    "    recalls = TP/(TP+FN)\n",
    "    f1_scores = 2 * precisions * recalls / (precisions + recalls)\n",
    "    overall_accuracy = np.sum(Y==y) / len(y)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    return precisions, recalls, f1_scores, overall_accuracy, mean_f1_score, TP, FP, FN\n",
    "    ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisions [%]:       [87.13235294 91.54411765]\n",
      "recalls    [%]:       [91.15384615 87.67605634]\n",
      "f1_scores  [%]:       [89.09774436 89.56834532]\n",
      "\n",
      "overall accuracy: 89.34%\n",
      "mean f1 score:    89.33%\n",
      "True Positive:[474 498]\n",
      "False Positive:[70 46]\n",
      "False Negative:[46 70]\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls, f1_scores, overall_accuracy, mean_f1_score,TrueP, FalseP, FalseN = compute_quality_metrics(classified, validace, 2)\n",
    "print('precisions [%]:      ', precisions*100)\n",
    "print('recalls    [%]:      ', recalls*100)\n",
    "print('f1_scores  [%]:      ', f1_scores*100)\n",
    "print('')\n",
    "print('overall accuracy: {:.2%}'.format(overall_accuracy))\n",
    "print('mean f1 score:    {:.2%}'.format(mean_f1_score))\n",
    "print('True Positive:' + str(TrueP) + '\\nFalse Positive:' + str(FalseP) + '\\nFalse Negative:' + str(FalseN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
