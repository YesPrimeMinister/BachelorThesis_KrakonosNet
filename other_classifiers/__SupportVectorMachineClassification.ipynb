{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier implementation\n",
    "Created for the bachelor thesis of Jakub Dvorak (2020) | jakub.dvorak@natur.cuni.cz<br>\n",
    "Department of Applied Geoinformatics and Cartography, Faculty of Science, Charles University\n",
    "\n",
    "Adapted from EduServ18 (2020): 3D Sensing, Scene Reconstruction and Semantic Interpretation<br>\n",
    "The original code was created by Martin Weinmann, Franz Rottensteiner and Dennis Wittich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__imports__ and __settings__ for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from sklearn.svm import SVC as SupportVectorMachine\n",
    "from sklearn.model_selection import GridSearchCV as GridSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV as RandomizedSearch\n",
    "import scipy.stats\n",
    "\n",
    "# GLOBAL SETTINGS\n",
    "PlotSize = 8                                     # Size of plots\n",
    "matplotlib.rcParams['figure.figsize'] = [PlotSize*2, PlotSize]  \n",
    "CMAP = matplotlib.colors.ListedColormap(['black', 'white', 'orange'])               # Color mapping \n",
    "np.set_printoptions(precision=2, suppress=True)  # Array print precision\n",
    "\n",
    "# CLASS AND FEATURE DESCRIPTION\n",
    "class_names = ['PICEA','PINUS','BACKGRD']\n",
    "feature_names = ['NIR','RED','GREEN','NDVI']\n",
    "num_classes = len(class_names); num_features = len(feature_names)\n",
    "\n",
    "# PATHS TO TRAIN/TEST DATA\n",
    "data_path = '../data/66_33/'\n",
    "training_set_path = data_path + 'train/'         # Relative path to training patch root folder\n",
    "test_set_path =     data_path + 'test/'         # Relative path to test patch root folder\n",
    "\n",
    "num_of_training_tiles = len(os.listdir(training_set_path + 'CIR/'))\n",
    "num_of_test_tiles = len(os.listdir(test_set_path + 'CIR/'))\n",
    "\n",
    "# USE CIR OR RGB DATA\n",
    "use_cir = True\n",
    "use_rgb = True\n",
    "patch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and handling\n",
    "Following function reads input data and creates np arrays out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patch(root_folder, cir, rgb):\n",
    "    ##########################################################\n",
    "    # READ IMAGES as FLOAT\n",
    "    if cir:\n",
    "        cir_file_list = os.listdir(root_folder + 'CIR/')\n",
    "        cir_list = []\n",
    "        \n",
    "        for file in cir_file_list:\n",
    "            cir_patch = imageio.imread(root_folder + 'CIR/' + file).astype(np.float32)\n",
    "            cir_patch = cir_patch * 1/255\n",
    "            \n",
    "            h, w = cir_patch.shape[:2]\n",
    "            num_samples = h*w\n",
    "            cir_list.append(cir_patch[:,:,:].reshape((num_samples, 3)))\n",
    "            del cir_patch\n",
    "\n",
    "        cir_features = np.concatenate(cir_list, axis=0)\n",
    "    \n",
    "    if rgb:\n",
    "        rgb_file_list = os.listdir(root_folder + 'RGB/')\n",
    "        rgb_list = []\n",
    "        \n",
    "        for file in rgb_file_list:\n",
    "            rgb_patch = imageio.imread(root_folder + 'RGB/' + file).astype(np.float32)\n",
    "            rgb_patch = rgb_patch * 1/255\n",
    "            \n",
    "            h, w = rgb_patch.shape[:2]\n",
    "            num_samples = h*w\n",
    "            rgb_list.append(rgb_patch[:,:,:].reshape((num_samples, 3)))\n",
    "            del rgb_patch\n",
    "        \n",
    "        rgb_features = np.concatenate(rgb_list, axis=0)\n",
    "\n",
    "\n",
    "    if cir and rgb:\n",
    "        features = np.concatenate([cir_features, rgb_features], axis=1)\n",
    "    elif cir:\n",
    "        features = cir_features\n",
    "    elif rgb:\n",
    "        features = rgb_features\n",
    "    else:\n",
    "        print('No valid data input.')\n",
    "\n",
    "\n",
    "    gt_file_list = os.listdir(root_folder + 'GT/')\n",
    "    gt_list = []\n",
    "\n",
    "    for file in gt_file_list:\n",
    "        gt_patch = imageio.imread(root_folder + 'GT/' + file).astype(np.float32)\n",
    " \n",
    "        h, w = gt_patch.shape[:2]\n",
    "        num_samples = h*w\n",
    "    \n",
    "        gt_list.append(gt_patch[:,:].reshape((num_samples)))\n",
    "        del gt_patch\n",
    "\n",
    "    ground_truth = np.concatenate(gt_list, axis=0)\n",
    "\n",
    "    ########################################################## \n",
    "    return features, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "X, y = read_patch(training_set_path, use_cir, use_rgb)\n",
    "b = time.time()\n",
    "X_t, y_t = read_patch(test_set_path, use_cir, use_rgb)\n",
    "c = time.time()\n",
    "\n",
    "print('Training set loaded in ' + str(b-a) + 's')\n",
    "print('Testing set loaded in ' + str(c-b) + 's')\n",
    "print(X_t.shape)\n",
    "print(y.shape)\n",
    "print(X.max())\n",
    "print(X.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation function\n",
    "The following function visualises IRRG, ground truth and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rgb_cir_gt_pred(tile_index, data, gt, pred, num_of_tiles, cir, rgb, size):\n",
    "    # Function to plot prediction vs ground truth\n",
    "    \n",
    "    # Split the datasets into tiles\n",
    "    data_list = np.split(data, num_of_tiles)\n",
    "    gt_list =   np.split(gt,   num_of_tiles)\n",
    "    pred_list = np.split(pred, num_of_tiles)\n",
    "    \n",
    "    # Select tile by tile_index and reshape to original dimensions\n",
    "    data = data_list[tile_index].reshape((size,size,data.shape[1]))\n",
    "    gt   = gt_list[tile_index].reshape((size,size))\n",
    "    pred = pred_list[tile_index].reshape((size,size))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(facecolor='white')\n",
    "    \n",
    "    if cir and rgb:\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(data[:,:,:3])\n",
    "        plt.title('NIR Red Green composite')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(data[:,:,-3:])\n",
    "        plt.title('Red Green Blue composite')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(gt, CMAP)\n",
    "        plt.title('GT Labels')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(pred, CMAP)\n",
    "        plt.title('Predicted Labels')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    elif cir or rgb:\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(data)\n",
    "        if cir:\n",
    "            plt.title('NIR Red Green composite')\n",
    "        else:\n",
    "            plt.title('Red Green Blue composite')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(gt, CMAP)\n",
    "        plt.title('GT Labels')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred, CMAP)\n",
    "        plt.title('Predicted Labels')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test of the created visualisation function\n",
    "plot_rgb_cir_gt_pred(3, X, y, y, num_of_training_tiles, use_cir, use_rgb, patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics\n",
    "The following function returns accuracy metrics, namely overall accuracy, precision, recall and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_metrics(Y, y, C):\n",
    "    # Copy the code from the last lab here\n",
    "    ##########################################################\n",
    "    M = np.equal(Y,y).astype(np.int)\n",
    "    TP = np.array([np.sum( M * (Y==i).astype(np.int)) for i in range(C)])\n",
    "    FP = np.array([np.sum( (1-M) * (Y==i)) for i in range(C)])\n",
    "    FN = np.array([np.sum( (1-M) * (y==i)) for i in range(C)])\n",
    "\n",
    "    precisions = TP/(TP+FP)\n",
    "    recalls = TP/(TP+FN)\n",
    "    f1_scores = 2 * precisions * recalls / (precisions + recalls)\n",
    "    overall_accuracy = np.sum(Y==y) / len(y)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    return precisions, recalls, f1_scores, overall_accuracy, mean_f1_score, TP, FP, FN\n",
    "    ##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier #2\n",
    "using uniformly distributed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training_subset(X, y, N_s):\n",
    "    ##########################################################\n",
    "    Xy = np.hstack((X,y.reshape((-1, 1))))\n",
    "    np.random.shuffle(Xy)\n",
    "    \n",
    "    X_s = Xy[:N_s, :-1]\n",
    "    y_s = Xy[:N_s, -1]        \n",
    "    ##########################################################\n",
    "    return X_s, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_training_subset(X, y, N_s, num_classes=3):\n",
    "    ##########################################################\n",
    "    N, F = X.shape\n",
    "    counts = np.zeros(num_classes)\n",
    "    num_drawn = 0\n",
    "    X_s = np.zeros((N_s, F), dtype=np.float32)\n",
    "    y_s = np.zeros((N_s,), dtype=np.float32)\n",
    "    \n",
    "    while(num_drawn < N_s):\n",
    "        i = np.random.randint(N)\n",
    "        yi = y[i]\n",
    "        if yi == np.argmin(counts):\n",
    "            counts[int(yi)] += 1\n",
    "            X_s[num_drawn] = X[i]\n",
    "            y_s[num_drawn] = yi\n",
    "            num_drawn += 1\n",
    "    ##########################################################\n",
    "    return X_s, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_s = 3000\n",
    "#X_rs, y_rs = get_random_training_subset(X, y, N_s)\n",
    "a = time.time()\n",
    "X_es, y_es = get_uniform_training_subset(X, y, N_s, 3)\n",
    "b = time.time()\n",
    "print(str(b-a))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_es,bins=range(6), rwidth=0.9, align='left')\n",
    "plt.title('random sampling')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_es,bins=range(6), rwidth=0.9, align='left')\n",
    "plt.title('uniformly dist.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fixed parameters for the SVM\n",
    "fixed_parameters_svm = {\n",
    "    'kernel' : 'rbf',                        # Define the kernel function\n",
    "    'cache_size' : 40000,\n",
    "    }\n",
    "\n",
    "# Tunable parameters for the SVM\n",
    "tunable_parameters_svm = { \n",
    "    'C': [1e0,1e1,1e2,1e3,1e4], # scipy.stats.expon([1]),             # Define the penalty value\n",
    "    'gamma': [0.1,1e0,10,100] #scipy.stats.expon(scale=.1)     # Kernel parameter\n",
    "}\n",
    "\n",
    "# Create an instance of the model that is to be optimized\n",
    "model = SupportVectorMachine(**fixed_parameters_svm)\n",
    "\n",
    "# Create the optimizer and run the optimization\n",
    "opt = GridSearch(model, tunable_parameters_svm, cv = 3, scoring=\"f1_macro\", refit=False, verbose=1, n_jobs=-1)\n",
    "opt.fit(X_es, y_es) #X_es, y_es)\n",
    "\n",
    "# Save and print optimal parameters\n",
    "opt_parameters_svm = opt.best_params_\n",
    "\n",
    "print(\"Best found parameters:\", opt_parameters_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the SVM classifier\n",
    "parameters_svm = {\n",
    "    'kernel' : 'rbf',                        # Define the kernel function\n",
    "    'cache_size' : 40000,\n",
    "    'C' : 1e4,\n",
    "    'gamma' : 1\n",
    "}\n",
    "\n",
    "svm_r = SupportVectorMachine(**parameters_svm)\n",
    "\n",
    "# Train the classifier\n",
    "a = time.time()\n",
    "svm_r.fit(X_es, y_es)\n",
    "b = time.time()\n",
    "\n",
    "print('Training finished in ' + str(b-a) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "jobs = 388\n",
    "Y_t = np.empty_like(y_t)\n",
    "Y_t_list = np.split(Y_t, jobs)\n",
    "X_t_list = np.split(X_t, jobs)\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print(Y_t_list[0].shape)\n",
    "print(X_t_list[0].shape)\n",
    "for i in range(jobs):\n",
    "    Y_t_list[i][:] = svm_r.predict(X_t_list[i][:])\n",
    "    print('Processed tile # ' + str(i))\n",
    "c = time.time()\n",
    "\n",
    "print('Inferrence finished in ' + str(c-b) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precisions, recalls, f1_scores, overall_accuracy, mean_f1_score,TrueP, FalseP, FalseN = compute_quality_metrics(Y_t, y_t, 3)\n",
    "print('precisions [%]:      ', precisions*100)\n",
    "print('recalls    [%]:      ', recalls*100)\n",
    "print('f1_scores  [%]:      ', f1_scores*100)\n",
    "print('')\n",
    "print('overall accuracy: {:.2%}'.format(overall_accuracy))\n",
    "print('mean f1 score:    {:.2%}'.format(mean_f1_score))\n",
    "print('True Positive:' + str(TrueP) + '\\nFalse Positive:' + str(FalseP) + '\\nFalse Negative:' + str(FalseN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rgb_cir_gt_pred(18, X_t, y_t, Y_t, num_of_test_tiles, use_cir, use_rgb, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(data_path + 'svm.csv', Y_t, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/33_66/'\n",
    "training_set_path = data_path + 'train/'         # Relative path to training patch root folder\n",
    "test_set_path =     data_path + 'test/'         # Relative path to test patch root folder\n",
    "\n",
    "num_of_training_tiles = len(os.listdir(training_set_path + 'CIR/'))\n",
    "num_of_test_tiles = len(os.listdir(test_set_path + 'CIR/'))\n",
    "\n",
    "a = time.time()\n",
    "X, y = read_patch(training_set_path, use_cir, use_rgb)\n",
    "b = time.time()\n",
    "X_t, y_t = read_patch(test_set_path, use_cir, use_rgb)\n",
    "c = time.time()\n",
    "\n",
    "print('Training set loaded in ' + str(b-a) + 's')\n",
    "print('Testing set loaded in ' + str(c-b) + 's')\n",
    "\n",
    "X_es, y_es = get_uniform_training_subset(X, y, N_s, 3)\n",
    "\n",
    "# Generate the SVM classifier\n",
    "parameters_svm = {\n",
    "    'kernel' : 'rbf',                        # Define the kernel function\n",
    "    'cache_size' : 40000,\n",
    "    'C' : 1e4,\n",
    "    'gamma' : 1\n",
    "}\n",
    "\n",
    "svm_r = SupportVectorMachine(**parameters_svm)\n",
    "\n",
    "# Train the classifier\n",
    "a = time.time()\n",
    "svm_r.fit(X_es, y_es)\n",
    "b = time.time()\n",
    "\n",
    "print('Training finished in ' + str(b-a) + 's')\n",
    "\n",
    "# Perform prediction\n",
    "jobs = num_of_test_tiles\n",
    "Y_t = np.empty_like(y_t)\n",
    "Y_t_list = np.split(Y_t, jobs)\n",
    "X_t_list = np.split(X_t, jobs)\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print(Y_t_list[0].shape)\n",
    "print(X_t_list[0].shape)\n",
    "for i in range(jobs):\n",
    "    Y_t_list[i][:] = svm_r.predict(X_t_list[i][:])\n",
    "    print('Processed tile # ' + str(i))\n",
    "c = time.time()\n",
    "\n",
    "print('Inferrence finished in ' + str(c-b) + 's')\n",
    "precisions, recalls, f1_scores, overall_accuracy, mean_f1_score,TrueP, FalseP, FalseN = compute_quality_metrics(Y_t, y_t, 3)\n",
    "print('precisions [%]:      ', precisions*100)\n",
    "print('recalls    [%]:      ', recalls*100)\n",
    "print('f1_scores  [%]:      ', f1_scores*100)\n",
    "print('')\n",
    "print('overall accuracy: {:.2%}'.format(overall_accuracy))\n",
    "print('mean f1 score:    {:.2%}'.format(mean_f1_score))\n",
    "print('True Positive:' + str(TrueP) + '\\nFalse Positive:' + str(FalseP) + '\\nFalse Negative:' + str(FalseN))\n",
    "\n",
    "plot_rgb_cir_gt_pred(18, X_t, y_t, Y_t, num_of_test_tiles, use_cir, use_rgb, patch_size)\n",
    "\n",
    "np.savetxt(data_path + 'svm.csv', Y_t, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/01_99/'\n",
    "training_set_path = data_path + 'train/'         # Relative path to training patch root folder\n",
    "test_set_path =     data_path + 'test/'         # Relative path to test patch root folder\n",
    "\n",
    "num_of_training_tiles = len(os.listdir(training_set_path + 'CIR/'))\n",
    "num_of_test_tiles = len(os.listdir(test_set_path + 'CIR/'))\n",
    "\n",
    "a = time.time()\n",
    "X, y = read_patch(training_set_path, use_cir, use_rgb)\n",
    "b = time.time()\n",
    "X_t, y_t = read_patch(test_set_path, use_cir, use_rgb)\n",
    "c = time.time()\n",
    "\n",
    "print('Training set loaded in ' + str(b-a) + 's')\n",
    "print('Testing set loaded in ' + str(c-b) + 's')\n",
    "\n",
    "X_es, y_es = get_uniform_training_subset(X, y, N_s, 3)\n",
    "\n",
    "# Generate the SVM classifier\n",
    "parameters_svm = {\n",
    "    'kernel' : 'rbf',                        # Define the kernel function\n",
    "    'cache_size' : 40000,\n",
    "    'C' : 1e4,\n",
    "    'gamma' : 1\n",
    "}\n",
    "\n",
    "svm_r = SupportVectorMachine(**parameters_svm)\n",
    "\n",
    "# Train the classifier\n",
    "a = time.time()\n",
    "svm_r.fit(X_es, y_es)\n",
    "b = time.time()\n",
    "\n",
    "print('Training finished in ' + str(b-a) + 's')\n",
    "\n",
    "# Perform prediction\n",
    "jobs = num_of_test_tiles\n",
    "Y_t = np.empty_like(y_t)\n",
    "Y_t_list = np.split(Y_t, jobs)\n",
    "X_t_list = np.split(X_t, jobs)\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "print(Y_t_list[0].shape)\n",
    "print(X_t_list[0].shape)\n",
    "for i in range(jobs):\n",
    "    Y_t_list[i][:] = svm_r.predict(X_t_list[i][:])\n",
    "    print('Processed tile # ' + str(i))\n",
    "c = time.time()\n",
    "\n",
    "print('Inferrence finished in ' + str(c-b) + 's')\n",
    "precisions, recalls, f1_scores, overall_accuracy, mean_f1_score,TrueP, FalseP, FalseN = compute_quality_metrics(Y_t, y_t, 3)\n",
    "print('precisions [%]:      ', precisions*100)\n",
    "print('recalls    [%]:      ', recalls*100)\n",
    "print('f1_scores  [%]:      ', f1_scores*100)\n",
    "print('')\n",
    "print('overall accuracy: {:.2%}'.format(overall_accuracy))\n",
    "print('mean f1 score:    {:.2%}'.format(mean_f1_score))\n",
    "print('True Positive:' + str(TrueP) + '\\nFalse Positive:' + str(FalseP) + '\\nFalse Negative:' + str(FalseN))\n",
    "\n",
    "plot_rgb_cir_gt_pred(18, X_t, y_t, Y_t, num_of_test_tiles, use_cir, use_rgb, patch_size)\n",
    "\n",
    "np.savetxt(data_path + 'svm.csv', Y_t, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
